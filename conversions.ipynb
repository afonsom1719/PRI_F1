{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def lap_time_to_milliseconds(time_str):\n",
    "    if pd.notna(time_str):\n",
    "        # Regular expression pattern to match the time components\n",
    "        time_pattern = r'(?:(\\d+):)?(\\d+):(\\d+\\.\\d+)'\n",
    "        match = re.match(time_pattern, time_str)\n",
    "\n",
    "        if match:\n",
    "            # Extract hours, minutes, seconds, and milliseconds\n",
    "            hours, minutes, seconds = match.groups()\n",
    "            if hours:\n",
    "                total_time = int(hours) * 3600000 + int(minutes) * 60000 + float(seconds) * 1000\n",
    "            else:\n",
    "                total_time = int(minutes) * 60000 + float(seconds) * 1000\n",
    "\n",
    "            return int(total_time)\n",
    "    return None  # Return None for null values\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "lap_time = \"1:38.109\"\n",
    "milliseconds = lap_time_to_milliseconds(lap_time)\n",
    "print(milliseconds)  # Output: 98109\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- QUALIFYING -----\n",
    "\n",
    "# Convert qualifying times to milliseconds and add the new columns to the qualifying dataset\n",
    "qualifying_dataset = pd.read_json(\"./f1db_json/qualifying.json\")\n",
    "\n",
    "qualifying_dataset[\"q1_ms\"] = qualifying_dataset[\"q1\"].apply(lambda x: lap_time_to_milliseconds(x))\n",
    "qualifying_dataset[\"q2_ms\"] = qualifying_dataset[\"q2\"].apply(lambda x: lap_time_to_milliseconds(x))\n",
    "qualifying_dataset[\"q3_ms\"] = qualifying_dataset[\"q3\"].apply(lambda x: lap_time_to_milliseconds(x))\n",
    "\n",
    "# Convert all q1_ms, q2_ms, and q3_ms values to integers\n",
    "\n",
    "qualifying_dataset[\"q1_ms\"] = qualifying_dataset[\"q1_ms\"].astype(\"Int64\")\n",
    "qualifying_dataset[\"q2_ms\"] = qualifying_dataset[\"q2_ms\"].astype(\"Int64\")\n",
    "qualifying_dataset[\"q3_ms\"] = qualifying_dataset[\"q3_ms\"].astype(\"Int64\")\n",
    "\n",
    "#print(qualifying_dataset.head())\n",
    "\n",
    "# export to json with file suffix of milliseconds\n",
    "\n",
    "qualifying_dataset.to_json(\"./f1db_json/qualifying_ms.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- RESULTS -----\n",
    "\n",
    "results_dataset = pd.read_json(\"./f1db_json/results.json\")\n",
    "\n",
    "results_dataset[\"fastestLapTime_ms\"] = results_dataset[\"fastestLapTime\"].apply(lambda x: lap_time_to_milliseconds(x))\n",
    "\n",
    "# convert fastestLapTime_ms to int\n",
    "\n",
    "results_dataset[\"fastestLapTime_ms\"] = results_dataset[\"fastestLapTime_ms\"].astype('Int64')\n",
    "\n",
    "#print(results_dataset.head())\n",
    "\n",
    "# export to json with file suffix of milliseconds\n",
    "\n",
    "results_dataset.to_json(\"./f1db_json/results_ms.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SPRINT RESULTS -----\n",
    "\n",
    "sresults_dataset = pd.read_json(\"./f1db_json/sprint_results.json\")\n",
    "\n",
    "sresults_dataset[\"fastestLapTime_ms\"] = sresults_dataset[\"fastestLapTime\"].apply(lambda x: lap_time_to_milliseconds(x))\n",
    "\n",
    "# convert fastestLapTime_ms to int\n",
    "\n",
    "sresults_dataset[\"fastestLapTime_ms\"] = results_dataset[\"fastestLapTime_ms\"].astype('Int64')\n",
    "\n",
    "#print(sresults_dataset.head())\n",
    "\n",
    "# export to json with file suffix of milliseconds\n",
    "\n",
    "sresults_dataset.to_json(\"./f1db_json/sprint_results_ms.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "races_dataset = pd.read_json(\"./f1db_json/races.json\", convert_dates=False)\n",
    "\n",
    "def concat_date_time(date_str, time_str):\n",
    "    if pd.notna(date_str):\n",
    "        # If date_str is a Timestamp, extract the date part\n",
    "        if isinstance(date_str, pd.Timestamp):\n",
    "            date_str = date_str.date().isoformat()\n",
    "        # If time_str is not available, use '00:00:00Z'\n",
    "        if not pd.notna(time_str):\n",
    "            time_str = '00:00:00'\n",
    "        return f\"{date_str}T{time_str}Z\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create a new column 'datetime' by combining 'date' and 'time'\n",
    "races_dataset['datetime'] = races_dataset.apply(lambda row: concat_date_time(row['date'], row['time']), axis=1)\n",
    "\n",
    "# Create similar columns for other fields (fp1, fp2, fp3, quali)\n",
    "for session in ['fp1', 'fp2', 'fp3', 'quali', 'sprint']:\n",
    "    date_col = f'{session}_date'\n",
    "    time_col = f'{session}_time'\n",
    "    datetime_col = f'{session}_datetime'\n",
    "    races_dataset[datetime_col] = races_dataset.apply(lambda row: concat_date_time(row[date_col], row[time_col]), axis=1)\n",
    "\n",
    "# Export to JSON with file suffix of 'datetime'\n",
    "races_dataset.to_json(\"./f1db_json/races_datetime.json\", orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crossover pitstop time field with date from races.json to get pitstop datetime field working\n",
    "\n",
    "races_dataset = pd.read_json(\"./f1db_json/races.json\", convert_dates=False)\n",
    "pitstops_dataset = pd.read_json(\"./f1db_json/pit_stops.json\", convert_dates=False)\n",
    "\n",
    "# Create a new column 'datetime' by combining 'date' from the corresponding race (raceId) and 'time' from pit_stops, using the concat_date_time function\n",
    "\n",
    "def get_race_date(raceId):\n",
    "    row = races_dataset[races_dataset['raceId'] == raceId]\n",
    "    if not row.empty:\n",
    "        return row['date'].values[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "pitstops_dataset['datetime'] = pitstops_dataset.apply(lambda row: concat_date_time(get_race_date(row['raceId']), row['time']), axis=1)\n",
    "\n",
    "# Export to JSON with file suffix of 'datetime'\n",
    "pitstops_dataset.to_json(\"./f1db_json/pit_stops_datetime.json\", orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
